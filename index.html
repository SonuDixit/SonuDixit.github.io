<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sonu Dixit</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Sonu Dixit</h1>
        <nav>
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#education">Education</a></li>
                <!-- <li><a href="#projects">Projects</a></li> -->
                <!-- <li><a href="paper_reading_summary.html">Paper Reading Summary</a></li> -->
                <li><a href="#contact">Contact</a></li>
                <li><a href="cv.html">CV</a></li>
            </ul>
        </nav>
    </header>
    <div class="intro", id="about">
        <h2>About Me </h2>
        <div class="content">
        <p>Hello! I am passionate about applying mathematics and neural networks to solve real-world problems. 
            With a strong foundation in AI and hands-on experience across diverse domains, I have worked on LLM fine-tuning, large-scale information retrieval, question-answering, and reinforcement learning. 
            Please refer to the experience section for more details on my projects.  <br><br> Outside of work, I enjoy swimming, running, spending time in nature(long walks, treks).</p>
        <img src="images/linkedin_profile.jpeg" alt="Sonu Dixit">
        </div>
    </div>

    <section id="experience">
        <h2>Industry Experience</h2>
        <h3> LLama 3 Finetuing for Customer Chat Conversation </h3>
        <ul>
            <li>We finetune LLama 3.1 8B model on Agent Customer conversation data.<a href="project_details.html#llm_finetuning"> Details</a></li>
        </ul>
        <h3> Intent Classification </h3>
        <ul>
            <li> We classify customer queries into predefined intents to enable automated handling by our Chatbot. Our trained model outperforms the existing solution and LLMs including GPT-3.5.</li>
            <li> Transformer Based multiple network(s) training. <a href="project_details.html#intent_classification">Details</a></li>
        </ul>
        <h3>Knowledge Article Recommendation</h3>
        <ul>
            <li>Trained a DistilBERT on the MSMarco dataset to proactively recommend relevant articles, achieving comparable performance on the TREC21 and TREC20 datasets.</li>
            <li>Distillation, Multiple methods of scoring (query, passage) pair, tradeoff in scoring,represetantion mechanism and final performance <a href="project_details.html#info_retrieval">Details</a> </li>
            <li>inspired from <a href="https://arxiv.org/abs/2104.06967"> Efficiently teaching an effective dense retriever with balanced topic aware sampling</a></li>
        </ul>
        <h3>Answer Recommendation, Generation</h3>
        <ul>
            <li>Recommended relevant queries and answers from a Knowledge Base, outperforming existing methods.</li>
            <li>Generate answer conditioned on recommendations, inspired from <a href="https://arxiv.org/abs/2110.07752"> Posterior guided training for retrievers</a> and <a href="https://arxiv.org/abs/1811.01241">Knowledge powered conversational agents </a></li>
            <li>End to end training of RAG systems</li>
        </ul>
        
        <h3>LLM as Co-Pilot</h3>
        <ul>
            <li>Utilized LLMs to generate contextually relevant responses during conversations, augmenting the LLM context with relevant historical information.</li>
            <li>Designed an identity task <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">(similar to Needle in a Haystack)</a> for our context.</li>
        </ul>

        <h3>Named Entity Recognition by Question Answering</h3>
        <ul>
            <li> Different clients need different granular entities(start_date_of_reservation, flight_time, ..). Traditional NER requires training data for the specific entities. </li>
            <li> We formulate this as QA problem, where question is asked for client specific entities. Model needs to Generate/extract the answer(entity). The same underlying QA-system can generalise to multiple clients. </li>
            <li> It reduces client-specific entity extraction finetuning. </li>
        </ul>

        <h3> Content Analysis and Storyline Extraction</h3>
        <ul>
            <li>Quantified character attributes using text, image, and audio data, correlating features with viewership metrics.</li>
            <li>Episode vector learning, social relationship, face recognition. <a href="https://sites.google.com/view/contentunderstanding/home">Details</a></li>
        </ul>
        <h3>Entity extraction from Semi-Structured Documents</h3>
        <ul>
            <li> Used HMM to extract values corresponding to predefined keys from documents.</li>
        </ul>

    </section>
    <section id="publications">
        <h2>Publications</h2>
        <ul>
            <li>R Hazra*, <u>Sonu Dixit*</u> ,S Sen, NAACL 2021 workshop - ViGIL <a href="https://vigilworkshop.github.io/static/papers-2021/13.pdf">Zero-Shot Generalization using Intrinsically Motivated Compositional Emergent Protocols</a>  <a href="https://sites.google.com/view/compositional-comm">website</a></li>
            <li>R Hazra, <u>Sonu Dixit</u>, NAACL 2021 workshop - ViGIL <a href="https://vigilworkshop.github.io/static/papers-2021/16.pdf">gComm: An environment for investigating generalization in Grounded Language Acquisition</a>  </li>
        </ul>
    </section>
    <section id="education">
        <h2>Education</h2>
        <p><strong>Indian Institute of Science (2017 – 2019)</strong><br> Masters - MTech (Artificial Intelligence), Overall GPA: 7.5/10</p>
        <p><strong>Gurukula Kangri University (2012 – 2016)</strong><br> Bachelors - BTech (Computer Science), Overall percentage: 78.60</p>
    </section>
    <section id="projects">
        <h2>Masters Thesis</h2>
        <h3>Adaptive Traffic Signal Control</h3>
        <ul>
            <li>Implemented multi-agent reinforcement learning (MARL) to dynamically adjust traffic signal durations based on congestion.</li>
            <li>Algorithm: Proximal Policy Optimization (PPO) with Advantage Actor-Critic. <a href="https://github.com/SonuDixit/Traffic/blob/master/mtech_project_report_results/report.pdf">Report</a></li>
            <li>Simulated traffic data using PTV Vissim and demonstrated MARL’s superiority over fixed-time algorithms in terms of average speed, delay, and lane occupancy. <a href="https://github.com/SonuDixit/Traffic/blob/master/mtech_project_report_results/mtech_project.pdf">Results</a></li>
            <li>Each Signal is represented as a Neural Network. During training multiple small neural networks are trained at same time. The networks are connected via the reward that they get.</li>
            <li>Advisor - <a href="https://www.csa.iisc.ac.in/~shalabh/">Prof Shalabh Bhatnagar</a> </li>
        </ul>
    </section>
    <section id="contact">
        <h2>Contact</h2>
        <p>Email: <a href="mailto:sonudixit2k@gmail.com">sonudixit2k@gmail.com</a></p>
        <p>LinkedIn: <a href="https://www.linkedin.com/in/sonudixit/">linkedin.com/in/sonudixit</a></p>
    </section>
    <!-- <footer>
        <p>&copy; 2024 Sonu Dixit. All rights reserved.</p>
    </footer> -->
</body>
</html>
